{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICY_DATA = '../data/datastorm_policy_data.csv'\n",
    "AGENT_DATA = '../data/datastorm_agent_data.csv'\n",
    "TEST_DATA = '../data/testset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(TEST_DATA, index_col='map_client_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agent = pd.read_csv(AGENT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(POLICY_DATA, parse_dates=['next_due_dt', 'termination_dt', \n",
    "                                           'main_holder_dob', 'spouse_dob', \n",
    "                                           'child1_dob', 'child2_dob', \n",
    "                                           'child3_dob', 'child4_dob', \n",
    "                                           'child5_dob', \n",
    "                                           'run_date', 'commencement_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_agent, on='agent_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['main_holder_occupation_cd', 'product_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicate columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['policy_code', 'client_code', 'policy_snapshot_as_on'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove policy snapshot with very small interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.policy_snapshot_as_on != 20190831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_term</th>\n",
       "      <th>policy_payment_mode</th>\n",
       "      <th>policy_status</th>\n",
       "      <th>commencement_dt</th>\n",
       "      <th>next_due_dt</th>\n",
       "      <th>termination_dt</th>\n",
       "      <th>termination_reason</th>\n",
       "      <th>main_holder_gender</th>\n",
       "      <th>main_holder_dob</th>\n",
       "      <th>main_holder_entry_age</th>\n",
       "      <th>...</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>status</th>\n",
       "      <th>substatus</th>\n",
       "      <th>termination_date</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cluster_code</th>\n",
       "      <th>supervisor_code</th>\n",
       "      <th>zone_code</th>\n",
       "      <th>region_code</th>\n",
       "      <th>designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>INFORCE</td>\n",
       "      <td>2011-08-21</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983-10-01</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2018/02/27</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>AUTOTERMINATED</td>\n",
       "      <td>2018/10/31</td>\n",
       "      <td>Colombo 03</td>\n",
       "      <td>LA01002</td>\n",
       "      <td>AG107931</td>\n",
       "      <td>ZONE105</td>\n",
       "      <td>RA262</td>\n",
       "      <td>Advisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>INFORCE</td>\n",
       "      <td>2006-07-14</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1958-01-01</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1998/10/02</td>\n",
       "      <td>INFORCED</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moratuwa</td>\n",
       "      <td>LA01001</td>\n",
       "      <td>AG100875</td>\n",
       "      <td>ZONE110</td>\n",
       "      <td>RA248</td>\n",
       "      <td>Advisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Y</td>\n",
       "      <td>INFORCE</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1967-11-01</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>2014/06/25</td>\n",
       "      <td>INFORCED</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batticaloa</td>\n",
       "      <td>LA01004</td>\n",
       "      <td>AG101697</td>\n",
       "      <td>ZONE107</td>\n",
       "      <td>RA231</td>\n",
       "      <td>Team Leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Q</td>\n",
       "      <td>INFORCE</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1989-10-01</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2014/03/20</td>\n",
       "      <td>INFORCED</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ratnapura</td>\n",
       "      <td>LA01002</td>\n",
       "      <td>AG104896</td>\n",
       "      <td>ZONE114</td>\n",
       "      <td>RA269</td>\n",
       "      <td>Advisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>LAPSED</td>\n",
       "      <td>2012-04-28</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>M</td>\n",
       "      <td>1988-05-01</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>2001/05/24</td>\n",
       "      <td>INFORCED</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wadduwa</td>\n",
       "      <td>LA01002</td>\n",
       "      <td>AG104545</td>\n",
       "      <td>ZONE114</td>\n",
       "      <td>RA257</td>\n",
       "      <td>Advisor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_term policy_payment_mode policy_status commencement_dt next_due_dt  \\\n",
       "0           20                   M       INFORCE      2011-08-21  2019-02-21   \n",
       "1           15                   M       INFORCE      2006-07-14  2019-09-14   \n",
       "2           20                   Y       INFORCE      2018-12-28  2019-12-28   \n",
       "3           15                   Q       INFORCE      2018-11-06  2020-02-06   \n",
       "4           15                   M        LAPSED      2012-04-28  2015-06-28   \n",
       "\n",
       "  termination_dt termination_reason main_holder_gender main_holder_dob  \\\n",
       "0            NaT                NaN                  M      1983-10-01   \n",
       "1            NaT                NaN                  F      1958-01-01   \n",
       "2            NaT                NaN                  M      1967-11-01   \n",
       "3            NaT                NaN                  M      1989-10-01   \n",
       "4            NaT             OTHERS                  M      1988-05-01   \n",
       "\n",
       "   main_holder_entry_age  ... date_joined      status       substatus  \\\n",
       "0                     28  ...  2018/02/27  TERMINATED  AUTOTERMINATED   \n",
       "1                     48  ...  1998/10/02    INFORCED          ACTIVE   \n",
       "2                     51  ...  2014/06/25    INFORCED          ACTIVE   \n",
       "3                     29  ...  2014/03/20    INFORCED          ACTIVE   \n",
       "4                     24  ...  2001/05/24    INFORCED          ACTIVE   \n",
       "\n",
       "   termination_date   city_name  cluster_code  supervisor_code  zone_code  \\\n",
       "0        2018/10/31  Colombo 03       LA01002         AG107931    ZONE105   \n",
       "1               NaN    Moratuwa       LA01001         AG100875    ZONE110   \n",
       "2               NaN  Batticaloa       LA01004         AG101697    ZONE107   \n",
       "3               NaN   Ratnapura       LA01002         AG104896    ZONE114   \n",
       "4               NaN     Wadduwa       LA01002         AG104545    ZONE114   \n",
       "\n",
       "   region_code  designation  \n",
       "0        RA262      Advisor  \n",
       "1        RA248      Advisor  \n",
       "2        RA231  Team Leader  \n",
       "3        RA269      Advisor  \n",
       "4        RA257      Advisor  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df, train_snap_date, label_last_date):\n",
    "    snap_df = df[(df.policy_snapshot_as_on == train_snap_date) \n",
    "                    & (df.policy_status == 'INFORCE')][['client_code', \n",
    "                                                        'policy_code', \n",
    "                                                        'product_name',\n",
    "                                                        'premium_value']]\n",
    "    cust_df = df[(df.policy_snapshot_as_on == train_snap_date)][[\n",
    "        'client_code']].drop_duplicates().set_index('client_code')\n",
    "\n",
    "    label_df = df[(df.policy_snapshot_as_on > train_snap_date) \n",
    "                     & (df.policy_snapshot_as_on <= label_last_date) \n",
    "                     & (df.policy_status == 'INFORCE')][['client_code', \n",
    "                                                         'product_name', \n",
    "                                                         'policy_code', \n",
    "                                                         'policy_snapshot_as_on',\n",
    "                                                         'premium_value']]\n",
    "    \n",
    "    join_df = label_df.merge(snap_df[['policy_code', 'client_code']], \n",
    "                             on=['policy_code', 'client_code'], how='left', \n",
    "                             indicator=True)\n",
    "    join_df['is_prev'] = join_df._merge.map({'left_only':0, 'both':1}).astype(int)\n",
    "    \n",
    "    #customers who can be c\n",
    "    cross_sell_eligible = join_df.groupby(['client_code', \n",
    "                                           'policy_snapshot_as_on']).is_prev.sum()\n",
    "    \n",
    "    cross_sell_eligible.name = 'cross_sell_eligible'\n",
    "    cross_sell_eligible = cross_sell_eligible[cross_sell_eligible > 0].reset_index()\n",
    "    \n",
    "    joined_cs_eligible = join_df.merge(cross_sell_eligible, \n",
    "                                       on=['client_code', \n",
    "                                           'policy_snapshot_as_on'], \n",
    "                                       how='left').dropna()\n",
    "    \n",
    "    labels = joined_cs_eligible[joined_cs_eligible.is_prev == 0][[\n",
    "    'client_code', 'product_name', 'premium_value']]\n",
    "    labels['premium_max'] = labels.groupby('client_code').premium_value.transform(max)\n",
    "    lab_filt = labels[labels.premium_value == labels.premium_max]\n",
    "    lab_filt = lab_filt.drop_duplicates(['client_code', 'product_name'], keep='first')\n",
    "    lab_filt = lab_filt[['client_code', 'product_name']]\n",
    "\n",
    "    return cust_df.merge(lab_filt, on='client_code', how='left').fillna(\"NONE\").set_index('client_code')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Client Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_dataset(df, snap_date):\n",
    "    df_snap = df[(df.policy_snapshot_as_on == snap_date)]\n",
    "    \n",
    "    df_snap.status = df_snap.status + '_AGENT'\n",
    "    \n",
    "    customer_specific_features = ['main_holder_gender', 'main_holder_dob',\n",
    "                               'main_holder_smoker_flag', 'spouse_gender',\n",
    "                               'spouse_dob', 'spouse_smoker_flag',\n",
    "                               'child1_dob', 'child1_gender', 'child2_dob',\n",
    "                               'child2_gender', 'child3_dob', 'child3_gender', \n",
    "                               'child4_dob', 'child4_gender', 'child5_dob', \n",
    "                               'child5_gender', 'main_holder_occupation', \n",
    "                               'client_code']\n",
    "    \n",
    "    df_cust = df_snap[customer_specific_features]\n",
    "\n",
    "    dob_feat = ['main_holder_dob', 'spouse_dob', 'child1_dob', 'child2_dob',\n",
    "           'child3_dob', 'child4_dob', 'child5_dob']\n",
    "\n",
    "    age_feat = []\n",
    "    for col in dob_feat:\n",
    "        new_col = col[:-4] + '_age'\n",
    "        df_cust[new_col] = pd.to_datetime(\n",
    "            snap_date, format='%Y%m%d').year - df_cust[col].dt.year\n",
    "        df_cust = df_cust.drop(columns=col)\n",
    "        age_feat.append(new_col)\n",
    "\n",
    "    df_cust_numeric = df_cust.groupby('client_code')[age_feat].median()\n",
    "\n",
    "    df_cust_cat = df_cust.select_dtypes('object').groupby('client_code').first()\n",
    "\n",
    "    df_cust_fin = df_cust_cat.join(df_cust_numeric)\n",
    "    \n",
    "    pivot_cols = ['policy_payment_mode', 'policy_status', 'payment_method', \n",
    "                  'status', 'gender']\n",
    "    \n",
    "    for col in pivot_cols:\n",
    "        df_filt = df_snap[['client_code'] + [col]].copy()\n",
    "        df_filt['value'] = 1\n",
    "        df_pivot = df_filt.pivot_table(values='value', \n",
    "                                       index='client_code', aggfunc='sum', \n",
    "                                       columns=col).fillna(0).astype(int)\n",
    "        df_cust_fin =df_cust_fin.join(\n",
    "            df_pivot.divide(df_pivot.sum(axis=1), axis=0), how='left')\n",
    "    \n",
    "    #policy age\n",
    "    df_policy_age = df_snap[['client_code', 'policy_snapshot_as_on', 'commencement_dt']]\n",
    "    \n",
    "    df_policy_age['policy_age'] = pd.cut(\n",
    "        ((pd.to_datetime(df_snap.policy_snapshot_as_on, format='%Y%m%d') - \n",
    "          df_snap.commencement_dt).dt.days/365),\n",
    "        bins=[-5,1,5,10,100], labels=['policy_age_1_yr', 'policy_age_5_yr', \n",
    "                                      'policy_age_10_yr', 'policy_age_40_yr'])\n",
    "    df_policy_age = df_policy_age.drop(columns=['policy_snapshot_as_on', 'commencement_dt'])\n",
    "\n",
    "    df_policy_age['value'] = 1\n",
    "    df_pivot = df_policy_age.pivot_table(values='value', \n",
    "                                           index='client_code', aggfunc='sum', \n",
    "                                       columns='policy_age').fillna(0).astype(int)\n",
    "    df_cust_fin = df_cust_fin.join(\n",
    "        df_pivot.divide(df_pivot.sum(axis=1), axis=0), how='left')\n",
    "    \n",
    "    #next due date\n",
    "    df_next_due = df_snap[['client_code', 'policy_snapshot_as_on', 'next_due_dt']]\n",
    "    df_next_due['next_due_age'] = pd.cut(((pd.to_datetime(\n",
    "        df_snap.policy_snapshot_as_on, format='%Y%m%d') - df_snap.next_due_dt).dt.days/365), \n",
    "                                         bins=[-100,-1,-0.2, 0, 0.2, 1, 100], \n",
    "                                         labels=['next_due_min_1_yr', \n",
    "                                                 'next_due_min_0.2_yr', \n",
    "                                                 'next_due_0_yr', \n",
    "                                                 'next_due_0.2_yr', \n",
    "                                                 'next_due_1_yr', \n",
    "                                                 'next_due_100_yr'])\n",
    "\n",
    "    df_next_due = df_next_due.drop(columns=['policy_snapshot_as_on', 'next_due_dt'])\n",
    "    df_next_due['value'] = 1\n",
    "    df_pivot = df_next_due.pivot_table(values='value', \n",
    "                                           index='client_code', aggfunc='sum', \n",
    "                                           columns='next_due_age').fillna(0).astype(int)\n",
    "    df_cust_fin = df_cust_fin.join(\n",
    "        df_pivot.divide(df_pivot.sum(axis=1), axis=0), how='left')\n",
    "    \n",
    "    ## Rider information\n",
    "    rider_sum_cols = ['rider1_sum_assuared', 'rider2_sum_assuared', \n",
    "                  'rider3_sum_assuared', 'rider4_sum_assuared', \n",
    "                  'rider5_sum_assuared', 'rider6_sum_assuared',\n",
    "                  'rider7_sum_assuared', 'rider8_sum_assuared', \n",
    "                  'rider9_sum_assuared', 'rider10_sum_assuared']\n",
    "\n",
    "    rider_prem_cols = ['rider1_prem', 'rider2_prem',\n",
    "           'rider3_prem', 'rider4_prem', 'rider5_prem',\n",
    "           'rider6_prem', 'rider7_prem', 'rider8_prem',\n",
    "           'rider9_prem', 'rider10_prem']\n",
    "\n",
    "    df_rider = df_snap[rider_sum_cols + rider_prem_cols + ['client_code']].copy()\n",
    "\n",
    "    df_rider['rider_count'] = (df_rider[rider_prem_cols] > 0).sum(axis=1)\n",
    "\n",
    "    df_rider['rider_prem'] = df_rider[rider_prem_cols].sum(axis=1)\n",
    "\n",
    "    df_rider['rider_sum_assured'] = df_rider[rider_sum_cols].sum(axis=1)\n",
    "\n",
    "    df_cust_fin = df_cust_fin.join(\n",
    "        df_rider.groupby('client_code')['rider_count', \n",
    "                                        'rider_prem', 'rider_sum_assured'\n",
    "                                       ].sum(), how='left')\n",
    "    \n",
    "    #Premium information\n",
    "    df_prem = df_snap[['client_code', 'premium_value', 'total_sum_assuared', \n",
    "                       'policy_payment_mode']].copy()\n",
    "    df_prem['monthly_premium'] = (df_prem.premium_value / \n",
    "                                  df_prem.policy_payment_mode.map({'M':1, \n",
    "                                                                   'Y':12, \n",
    "                                                                   'Q':3, \n",
    "                                                                   'H':6, \n",
    "                                                                   'S':float('inf')}))\n",
    "    df_prem = df_prem.drop(columns='policy_payment_mode')\n",
    "    df_cust_fin = df_cust_fin.join(df_prem.groupby('client_code').sum(), \n",
    "                                   how='left')\n",
    "\n",
    "    return df_cust_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_vals(df_cust):\n",
    "    cat_cols = ['main_holder_gender', 'main_holder_smoker_flag', 'spouse_gender',\n",
    "       'spouse_smoker_flag', 'child1_gender', 'child2_gender', 'child3_gender',\n",
    "       'child4_gender', 'child5_gender', 'main_holder_occupation']\n",
    "\n",
    "    df_cust[cat_cols] = df_cust[cat_cols].fillna('unk')\n",
    "\n",
    "    zero_fill_cols = ['spouse_age', 'child1_age', 'child2_age',\n",
    "           'child3_age', 'child4_age', 'child5_age']\n",
    "    df_cust[zero_fill_cols] = df_cust[zero_fill_cols].fillna(0)\n",
    "    \n",
    "    return df_cust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encoding(df_cust):\n",
    "    cat_cols = ['main_holder_gender', 'main_holder_smoker_flag', 'spouse_gender',\n",
    "           'spouse_smoker_flag', 'child1_gender', 'child2_gender', 'child3_gender',\n",
    "           'child4_gender', 'child5_gender', 'main_holder_occupation']\n",
    "\n",
    "    cat_enc = OrdinalEncoder(cols=cat_cols, verbose=False)\n",
    "\n",
    "    cat_enc.fit(df_cust)\n",
    "\n",
    "    df_cust = cat_enc.transform(df_cust)\n",
    "    \n",
    "    return df_cust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set_rec(df, snap_date, last_label_date):\n",
    "    df_labels = create_labels(df, snap_date, last_label_date)\n",
    "\n",
    "    df_cust = client_dataset(df, snap_date)\n",
    "\n",
    "    df_cust = fillna_vals(df_cust)\n",
    "    \n",
    "    df_cust = cat_encoding(df_cust)\n",
    "    df_cust = df_cust.drop(columns=['child4_age', \n",
    "                           'child5_age', \n",
    "                           'child5_gender', \n",
    "                           'child4_gender'])\n",
    "\n",
    "    df_cross_sell = df_labels    \n",
    "\n",
    "    return df_cust.join(df_cross_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set(df, snap_date, last_label_date):\n",
    "    df_labels = create_labels(df, snap_date, last_label_date)\n",
    "\n",
    "    df_cust = client_dataset(df, snap_date)\n",
    "\n",
    "    df_cust = fillna_vals(df_cust)\n",
    "    \n",
    "    df_cust = cat_encoding(df_cust)\n",
    "    df_cust = df_cust.drop(columns=['child4_age', \n",
    "                           'child5_age', \n",
    "                           'child5_gender', \n",
    "                           'child4_gender'])\n",
    "\n",
    "    df_cross_sell = (df_labels.product_name != 'NONE').astype(int)\n",
    "    df_cross_sell.name = 'is_cross_sell'\n",
    "    \n",
    "\n",
    "    return df_cust.join(df_cross_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_set(df, snap_date):\n",
    "    df_cust = client_dataset(df, snap_date)\n",
    "\n",
    "    df_cust = fillna_vals(df_cust)\n",
    "    \n",
    "    df_cust = cat_encoding(df_cust)\n",
    "    df_cust = df_cust.drop(columns=['child4_age', \n",
    "                           'child5_age', \n",
    "                           'child5_gender', \n",
    "                           'child4_gender'])\n",
    "    \n",
    "    return df_cust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross sell prediction Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test datasets\n",
    "\n",
    "train/test selected so that there are no overlapping time regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_snaps = sorted(df.policy_snapshot_as_on.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([create_train_set(df, policy_snaps[0], policy_snaps[6]),\n",
    "                      create_train_set(df, policy_snaps[1], policy_snaps[7]),\n",
    "                      create_train_set(df, policy_snaps[2], policy_snaps[8]),\n",
    "                      create_train_set(df, policy_snaps[3], policy_snaps[9]),\n",
    "                      create_train_set(df, policy_snaps[4], policy_snaps[10]),\n",
    "                      create_train_set(df, policy_snaps[5], policy_snaps[11]),\n",
    "                      create_train_set(df, policy_snaps[6], policy_snaps[12])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['main_holder_gender', 'main_holder_smoker_flag', 'spouse_gender',\n",
       "       'spouse_smoker_flag', 'child1_gender', 'child2_gender', 'child3_gender',\n",
       "       'main_holder_occupation', 'main_holder_age', 'spouse_age', 'child1_age',\n",
       "       'child2_age', 'child3_age', 'H', 'M', 'Q', 'S', 'Y', 'INFORCE',\n",
       "       'LAPSED', 'TERMINATED', 'CASH', 'CHEQUE', 'INFORCED_AGENT',\n",
       "       'SUSPENDED_AGENT', 'TERMINATED_AGENT', 'Female', 'Male',\n",
       "       'policy_age_1_yr', 'policy_age_5_yr', 'policy_age_10_yr',\n",
       "       'policy_age_40_yr', 'next_due_min_1_yr', 'next_due_min_0.2_yr',\n",
       "       'next_due_0_yr', 'next_due_0.2_yr', 'next_due_1_yr', 'next_due_100_yr',\n",
       "       'rider_count', 'rider_prem', 'rider_sum_assured', 'premium_value',\n",
       "       'total_sum_assuared', 'monthly_premium', 'is_cross_sell'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    159246\n",
       "1      4259\n",
       "Name: is_cross_sell, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.is_cross_sell.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_test = create_train_set(df, policy_snaps[12], policy_snaps[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df_train.drop(columns='is_cross_sell')\n",
    "train_y = df_train['is_cross_sell']\n",
    "\n",
    "test_X = df_test.drop(columns='is_cross_sell')\n",
    "test_y = df_test['is_cross_sell']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "model_rec = LGBMClassifier(class_weight='balanced')\n",
    "param_grid = {\"max_depth\": [None],\n",
    "              \"min_child_samples\": [10, 20, 40],\n",
    "              \"num_leaves\": [2, 3, 10],\n",
    "              \"n_estimators\": [100, 500, 800],\n",
    "              \"learning_rate\": [0.1,0.05,0.01]}\n",
    "gsLGBM = GridSearchCV(model_rec, param_grid=param_grid, cv=kfold, \n",
    "                      scoring=make_scorer(f1_score, average='macro'), \n",
    "                      n_jobs= 8, \n",
    "                      verbose = 1)\n",
    "\n",
    "gsLGBM.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(learning_rate=0.1, max_depth=6, min_child_samples=1000, n_estimators=300, num_leaves=3, random_state=2, class_weight='balanced')\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "pred_y = model.predict(test_X)\n",
    "pred_y_prob = model.predict_proba(test_X)[:,1]\n",
    "\n",
    "pred_y_train = model.predict(train_X)\n",
    "pred_y_train_prob = model.predict_proba(train_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20944  5902]\n",
      " [  211   356]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89    159246\n",
      "           1       0.09      0.70      0.15      4259\n",
      "\n",
      "    accuracy                           0.80    163505\n",
      "   macro avg       0.54      0.75      0.52    163505\n",
      "weighted avg       0.97      0.80      0.87    163505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87     26846\n",
      "           1       0.06      0.63      0.10       567\n",
      "\n",
      "    accuracy                           0.78     27413\n",
      "   macro avg       0.52      0.70      0.49     27413\n",
      "weighted avg       0.97      0.78      0.86     27413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796146280023456\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_y, pred_y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation prediction model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_snaps = sorted(df.policy_snapshot_as_on.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([create_train_set_rec(df, policy_snaps[0], policy_snaps[6]),\n",
    "                      create_train_set_rec(df, policy_snaps[1], policy_snaps[7]),\n",
    "                      create_train_set_rec(df, policy_snaps[2], policy_snaps[8]),\n",
    "                      create_train_set_rec(df, policy_snaps[3], policy_snaps[9]),\n",
    "                      create_train_set_rec(df, policy_snaps[4], policy_snaps[10]),\n",
    "                      create_train_set_rec(df, policy_snaps[5], policy_snaps[11]),\n",
    "                      create_train_set_rec(df, policy_snaps[6], policy_snaps[12])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['main_holder_gender', 'main_holder_smoker_flag', 'spouse_gender',\n",
       "       'spouse_smoker_flag', 'child1_gender', 'child2_gender', 'child3_gender',\n",
       "       'main_holder_occupation', 'main_holder_age', 'spouse_age', 'child1_age',\n",
       "       'child2_age', 'child3_age', 'H', 'M', 'Q', 'S', 'Y', 'INFORCE',\n",
       "       'LAPSED', 'TERMINATED', 'CASH', 'CHEQUE', 'INFORCED_AGENT',\n",
       "       'SUSPENDED_AGENT', 'TERMINATED_AGENT', 'Female', 'Male',\n",
       "       'policy_age_1_yr', 'policy_age_5_yr', 'policy_age_10_yr',\n",
       "       'policy_age_40_yr', 'next_due_min_1_yr', 'next_due_min_0.2_yr',\n",
       "       'next_due_0_yr', 'next_due_0.2_yr', 'next_due_1_yr', 'next_due_100_yr',\n",
       "       'rider_count', 'rider_prem', 'rider_sum_assured', 'premium_value',\n",
       "       'total_sum_assuared', 'monthly_premium', 'product_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_test = create_train_set_rec(df, policy_snaps[12], policy_snaps[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter only cross selled customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.product_name != 'NONE']\n",
    "df_test = df_test[df_test.product_name != 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df_train.drop(columns='product_name')\n",
    "train_y = df_train['product_name']\n",
    "\n",
    "test_X = df_test.drop(columns='product_name')\n",
    "test_y = df_test['product_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_rec = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced')\n",
    "model_rec = LGBMClassifier(learning_rate= 0.1,\n",
    "            max_depth= None,\n",
    "            min_child_samples= 20,\n",
    "            n_estimators= 800,\n",
    "            num_leaves= 10, class_weight='balanced', n_jobs=-1)\n",
    "model_rec.fit(train_X, train_y)\n",
    "\n",
    "pred_y = model_rec.predict(test_X)\n",
    "pred_y_prob = model_rec.predict_proba(test_X)\n",
    "\n",
    "pred_y_train = model_rec.predict(train_X)\n",
    "pred_y_train_prob = model_rec.predict_proba(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEALTH        2112\n",
       "INVESTMENT    1649\n",
       "RETIREMENT     395\n",
       "EDUCATION       79\n",
       "PROTECTION      24\n",
       "Name: product_name, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEALTH        298\n",
       "INVESTMENT    237\n",
       "RETIREMENT     27\n",
       "EDUCATION       3\n",
       "PROTECTION      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred_y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   3   1   0   0]\n",
      " [  1 166 101   0  12]\n",
      " [  0 109 126   0   9]\n",
      " [  0   1   0   2   0]\n",
      " [  0  19   9   0   6]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   EDUCATION       0.99      1.00      0.99        79\n",
      "      HEALTH       1.00      1.00      1.00      2112\n",
      "  INVESTMENT       1.00      1.00      1.00      1649\n",
      "  PROTECTION       0.96      1.00      0.98        24\n",
      "  RETIREMENT       0.99      1.00      0.99       395\n",
      "\n",
      "    accuracy                           1.00      4259\n",
      "   macro avg       0.99      1.00      0.99      4259\n",
      "weighted avg       1.00      1.00      1.00      4259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   EDUCATION       0.67      0.33      0.44         6\n",
      "      HEALTH       0.56      0.59      0.57       280\n",
      "  INVESTMENT       0.53      0.52      0.52       244\n",
      "  PROTECTION       1.00      0.67      0.80         3\n",
      "  RETIREMENT       0.22      0.18      0.20        34\n",
      "\n",
      "    accuracy                           0.53       567\n",
      "   macro avg       0.60      0.46      0.51       567\n",
      "weighted avg       0.53      0.53      0.53       567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub = create_pred_set(df, policy_snaps[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_pred.join(df_sub, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub = model.predict_proba(df_sub)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['probability_of_cross_sell'] = pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub[['probability_of_cross_sell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.index.name = 'map_client_cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_of_cross_sell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map_client_cd</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C100003</th>\n",
       "      <td>0.585098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100004</th>\n",
       "      <td>0.663047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100009</th>\n",
       "      <td>0.526187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100014</th>\n",
       "      <td>0.013891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100015</th>\n",
       "      <td>0.557611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154448</th>\n",
       "      <td>0.446167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154449</th>\n",
       "      <td>0.413168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154450</th>\n",
       "      <td>0.526058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154454</th>\n",
       "      <td>0.684784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154455</th>\n",
       "      <td>0.549120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19030 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               probability_of_cross_sell\n",
       "map_client_cd                           \n",
       "C100003                         0.585098\n",
       "C100004                         0.663047\n",
       "C100009                         0.526187\n",
       "C100014                         0.013891\n",
       "C100015                         0.557611\n",
       "...                                  ...\n",
       "C154448                         0.446167\n",
       "C154449                         0.413168\n",
       "C154450                         0.526058\n",
       "C154454                         0.684784\n",
       "C154455                         0.549120\n",
       "\n",
       "[19030 rows x 1 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\nisal_105136\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub_rec = create_pred_set(df, policy_snaps[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_rec = df_pred.join(df_sub_rec, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_y_prob_rec = model_rec.predict(df_sub_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INVESTMENT', 'INVESTMENT', 'INVESTMENT', ..., 'INVESTMENT',\n",
       "       'PROTECTION', 'PROTECTION'], dtype=object)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_y_prob_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_rec['recommendation'] = sub_y_prob_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_rec = df_sub_rec[['recommendation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INVESTMENT    9256\n",
       "HEALTH        9091\n",
       "RETIREMENT     651\n",
       "EDUCATION       27\n",
       "PROTECTION       5\n",
       "Name: recommendation, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub_rec.recommendation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_final = df_sub.join(df_sub_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_final.loc[df_sub_final.probability_of_cross_sell < 0.5, 'recommendation'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_of_cross_sell</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map_client_cd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C100003</th>\n",
       "      <td>0.585098</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100004</th>\n",
       "      <td>0.663047</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100009</th>\n",
       "      <td>0.526187</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100014</th>\n",
       "      <td>0.013891</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100015</th>\n",
       "      <td>0.557611</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154448</th>\n",
       "      <td>0.446167</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154449</th>\n",
       "      <td>0.413168</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154450</th>\n",
       "      <td>0.526058</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154454</th>\n",
       "      <td>0.684784</td>\n",
       "      <td>PROTECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C154455</th>\n",
       "      <td>0.549120</td>\n",
       "      <td>PROTECTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19030 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               probability_of_cross_sell recommendation\n",
       "map_client_cd                                          \n",
       "C100003                         0.585098     INVESTMENT\n",
       "C100004                         0.663047     INVESTMENT\n",
       "C100009                         0.526187     INVESTMENT\n",
       "C100014                         0.013891           None\n",
       "C100015                         0.557611     INVESTMENT\n",
       "...                                  ...            ...\n",
       "C154448                         0.446167           None\n",
       "C154449                         0.413168           None\n",
       "C154450                         0.526058     INVESTMENT\n",
       "C154454                         0.684784     PROTECTION\n",
       "C154455                         0.549120     PROTECTION\n",
       "\n",
       "[19030 rows x 2 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_final.to_csv('../submission/randomforestrangers_case_study_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "premium_value              285\n",
       "main_holder_age            283\n",
       "monthly_premium            275\n",
       "rider_prem                 261\n",
       "total_sum_assuared         261\n",
       "main_holder_occupation     256\n",
       "rider_sum_assured          241\n",
       "next_due_100_yr             94\n",
       "LAPSED                      94\n",
       "spouse_age                  88\n",
       "INFORCE                     75\n",
       "policy_age_1_yr             65\n",
       "child1_age                  47\n",
       "rider_count                 46\n",
       "child2_age                  39\n",
       "Female                      39\n",
       "next_due_1_yr               38\n",
       "policy_age_10_yr            37\n",
       "main_holder_gender          35\n",
       "next_due_0.2_yr             35\n",
       "SUSPENDED_AGENT             30\n",
       "policy_age_5_yr             28\n",
       "Q                           27\n",
       "INFORCED_AGENT              27\n",
       "child1_gender               26\n",
       "M                           26\n",
       "policy_age_40_yr            26\n",
       "next_due_min_0.2_yr         22\n",
       "spouse_gender               21\n",
       "S                           19\n",
       "TERMINATED_AGENT            18\n",
       "main_holder_smoker_flag     17\n",
       "child2_gender               17\n",
       "next_due_0_yr               16\n",
       "CASH                        16\n",
       "TERMINATED                  16\n",
       "Y                           14\n",
       "child3_age                  12\n",
       "H                           11\n",
       "child3_gender               10\n",
       "Male                         3\n",
       "next_due_min_1_yr            2\n",
       "spouse_smoker_flag           2\n",
       "CHEQUE                       0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.feature_importances_, index=train_X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shap Values\n",
    "import shap\n",
    "shap_train = train_X.sample(2000)\n",
    "shap_values = shap.TreeExplainer(model).shap_values(shap_train)\n",
    "shap.summary_plot(shap_values, shap_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
